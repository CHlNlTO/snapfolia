                  epoch,             train/loss,  metrics/accuracy_top1,  metrics/accuracy_top5,               val/loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                 2.1848,                0.91875,                0.99306,                 2.8726,             0.00023769,             0.00023769,             0.00023769
                      2,                0.46924,                0.93194,                0.99479,                 2.7591,             0.00045214,             0.00045214,             0.00045214
                      3,                0.29364,                0.97118,                0.99931,                 2.6843,             0.00064303,             0.00064303,             0.00064303
                      4,                0.21863,                0.97778,                0.99861,                 2.6752,             0.00060797,             0.00060797,             0.00060797
                      5,                0.15302,                0.98264,                0.99965,                 2.6648,             0.00057263,             0.00057263,             0.00057263
                      6,                0.12012,                 0.9809,                0.99896,                 2.6636,             0.00053728,             0.00053728,             0.00053728
                      7,                0.11084,                0.98507,                      1,                 2.6542,             0.00050194,             0.00050194,             0.00050194
                      8,                 0.0956,                0.98854,                      1,                 2.6532,              0.0004666,              0.0004666,              0.0004666
                      9,                0.08449,                0.98854,                0.99965,                  2.651,             0.00043126,             0.00043126,             0.00043126
                     10,                0.07137,                0.98993,                      1,                  2.649,             0.00039591,             0.00039591,             0.00039591
                     11,                0.06146,                0.98854,                0.99965,                 2.6487,             0.00036057,             0.00036057,             0.00036057
                     12,                0.06126,                0.98854,                0.99965,                  2.648,             0.00032523,             0.00032523,             0.00032523
                     13,                0.05322,                0.99236,                0.99965,                 2.6441,             0.00028988,             0.00028988,             0.00028988
                     14,                0.05166,                0.99028,                      1,                 2.6459,             0.00025454,             0.00025454,             0.00025454
                     15,                0.04462,                0.99097,                      1,                  2.646,              0.0002192,              0.0002192,              0.0002192
                     16,                0.03987,                 0.9934,                      1,                 2.6442,             0.00018385,             0.00018385,             0.00018385
                     17,                0.03572,                 0.9934,                      1,                 2.6433,             0.00014851,             0.00014851,             0.00014851
                     18,                0.03455,                0.99375,                0.99965,                 2.6424,             0.00011317,             0.00011317,             0.00011317
                     19,                0.03046,                0.99444,                0.99965,                 2.6428,             7.7826e-05,             7.7826e-05,             7.7826e-05
                     20,                0.02744,                 0.9934,                0.99965,                  2.643,             4.2483e-05,             4.2483e-05,             4.2483e-05
