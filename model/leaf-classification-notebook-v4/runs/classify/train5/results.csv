                  epoch,             train/loss,  metrics/accuracy_top1,  metrics/accuracy_top5,               val/loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                 2.2385,                 0.8726,                 0.9874,                 2.9212,              0.0002377,              0.0002377,              0.0002377
                      2,                0.55573,                0.94027,                0.99781,                 2.7541,             0.00045215,             0.00045215,             0.00045215
                      3,                 0.3344,                0.95479,                0.99836,                 2.7106,             0.00064304,             0.00064304,             0.00064304
                      4,                0.24547,                0.97644,                0.99945,                 2.6785,             0.00060797,             0.00060797,             0.00060797
                      5,                0.18189,                0.97726,                0.99918,                  2.672,             0.00057263,             0.00057263,             0.00057263
                      6,                0.13983,                0.97945,                0.99973,                 2.6694,             0.00053728,             0.00053728,             0.00053728
                      7,                0.12999,                0.97973,                0.99973,                 2.6629,             0.00050194,             0.00050194,             0.00050194
                      8,                0.10447,                0.98438,                      1,                 2.6575,              0.0004666,              0.0004666,              0.0004666
                      9,                0.08442,                0.98712,                0.99945,                 2.6523,             0.00043126,             0.00043126,             0.00043126
                     10,                0.08447,                0.98274,                0.99918,                 2.6564,             0.00039591,             0.00039591,             0.00039591
                     11,                0.07863,                0.98767,                0.99973,                 2.6503,             0.00036057,             0.00036057,             0.00036057
                     12,                0.06947,                0.98959,                0.99973,                 2.6474,             0.00032523,             0.00032523,             0.00032523
                     13,                 0.0639,                0.99151,                0.99973,                 2.6474,             0.00028988,             0.00028988,             0.00028988
                     14,                 0.0525,                0.98986,                      1,                 2.6465,             0.00025454,             0.00025454,             0.00025454
                     15,                0.04952,                0.99233,                      1,                 2.6442,              0.0002192,              0.0002192,              0.0002192
                     16,                0.04669,                0.99123,                0.99973,                  2.645,             0.00018385,             0.00018385,             0.00018385
                     17,                0.04202,                0.99068,                      1,                 2.6444,             0.00014851,             0.00014851,             0.00014851
                     18,                0.03666,                0.99315,                      1,                 2.6436,             0.00011317,             0.00011317,             0.00011317
                     19,                0.03964,                0.99288,                      1,                  2.643,             7.7826e-05,             7.7826e-05,             7.7826e-05
                     20,                0.03053,                0.99233,                      1,                 2.6433,             4.2483e-05,             4.2483e-05,             4.2483e-05
